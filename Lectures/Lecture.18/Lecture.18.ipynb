{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 18- Machine Learning with Scikit-Learn\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/) is a python library of a large number of Machine Learning Algorithms and utilities. Similar to numpy, it's interface is adopted or available by most other Machine Learnings packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for SUSY Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VarNames=[\"signal\", \"l_1_pT\", \"l_1_eta\",\"l_1_phi\", \"l_2_pT\", \"l_2_eta\", \"l_2_phi\", \"MET\", \"MET_phi\", \"MET_rel\", \"axial_MET\", \"M_R\", \"M_TR_2\", \"R\", \"MT2\", \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos_theta_r1\"]\n",
    "RawNames=[\"l_1_pT\", \"l_1_eta\",\"l_1_phi\", \"l_2_pT\", \"l_2_eta\", \"l_2_phi\", \"MET\", \"MET_phi\"]\n",
    "FeatureNames=list(set(VarNames[1:]).difference(RawNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"../../Labs/Lab.7/SUSY.csv\"\n",
    "df = pd.read_csv(filename, dtype='float64', names=VarNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig=df[df.signal==1]\n",
    "df_bkg=df[df.signal==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "\n",
    "### Define Input/Outputs\n",
    "\n",
    "### Establishing Train, Test, Validate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Train=4000000\n",
    "\n",
    "Train_Sample=df[:N_Train]\n",
    "Test_Sample=df[N_Train:]\n",
    "\n",
    "X_Train=Train_Sample[VarNames[1:]]\n",
    "y_Train=Train_Sample[\"signal\"]\n",
    "\n",
    "X_Test=Test_Sample[VarNames[1:]]\n",
    "y_Test=Test_Sample[\"signal\"]\n",
    "\n",
    "Test_sig=Test_Sample[Test_Sample.signal==1]\n",
    "Test_bkg=Test_Sample[Test_Sample.signal==0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML with Scikit-Learn\n",
    "\n",
    "Scikit-Learn provides a large library of ML algorithms with a common interface which makes it easy to try and compare algorithms.\n",
    "\n",
    "Last week we created a Fisher discriminant by computing the weights with numpy using the analytical solution. Lets use Scikit-Learn to do the same thing. \n",
    "\n",
    "First we instanciate the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.discriminant_analysis as DA\n",
    "# Instanciate Method\n",
    "Fisher=DA.LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher.fit(X_Train,y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can immediately apply the algorithm to get predictions (signal or background):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher.predict(X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the prediction doing here? \n",
    "* Applying the trained method to get an output (decision_function).\n",
    "* Using some threshold (most likely at 0) on the output assign to signal/background.\n",
    "\n",
    "From you previous lab, you should understand that the value of the threshold is something to be tuned and optimized. As you change the threshold, you move on the ROC curve exchanging TPR for FPR.\n",
    "\n",
    "So lets see the decision function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(Fisher.decision_function(Test_sig[VarNames[1:]]),bins=100,histtype=\"step\", color=\"blue\", label=\"signal\",stacked=True)\n",
    "plt.hist(Fisher.decision_function(Test_bkg[VarNames[1:]]),bins=100,histtype=\"step\", color=\"red\", label=\"background\",stacked=True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attempt to see what the predict function is doing by plotting the decision output for the signal selected signal and backgournd samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sig_pred = Test_sig[np.array(Fisher.predict(Test_sig[VarNames[1:]]),dtype=\"bool\")]\n",
    "plt.hist(Fisher.decision_function(sig_pred[VarNames[1:]]),bins=100,histtype=\"step\", color=\"blue\", label=\"signal\",stacked=True)\n",
    "bkg_pred = Test_bkg[np.array(Fisher.predict(Test_bkg[VarNames[1:]]),dtype=\"bool\")]\n",
    "plt.hist(Fisher.decision_function(bkg_pred[VarNames[1:]]),bins=100,histtype=\"step\", color=\"red\", label=\"background\",stacked=True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So predict is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher.decision_function(X_Test)>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the TPR and FPR, plot the ROC curve, and compute the AUC. We've done this before... this time lets use some utilities in Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_Test, Fisher.decision_function(X_Test))\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr,tpr,color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily compute other metrics, for example the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_Test, Fisher.predict(X_Test,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the threshold, if we like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=-0.1\n",
    "f1_score(y_Test, np.array(Fisher.decision_function(X_Test)>threshold,dtype='int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that FPR, TPR, ROC, and AUC do not depend on how much the signal to background ratio. Other metrics, like the f1 score, do depend on the mixture. A common mistake is to quote f1 scores without specifying the signal to background mixture. Lets compute the f1 score with a different mixture of signal and background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sig = X_Test[y_Test==1]\n",
    "y_sig = y_Test[y_Test==1]\n",
    "\n",
    "X_bkg = X_Test[y_Test==0]\n",
    "y_bkg = y_Test[y_Test==0]\n",
    "\n",
    "print(\"Sig f1 score:\", f1_score(y_sig, Fisher.predict(X_sig)))\n",
    "print(\"Bkg f1 score:\", f1_score(y_bkg, Fisher.predict(X_bkg)))\n",
    "\n",
    "N_sig=1000\n",
    "N_bkg=100000\n",
    "X_mix = np.concatenate((X_sig[:N_sig],X_bkg[:N_bkg]))\n",
    "y_mix = np.concatenate((y_sig[:N_sig],y_bkg[:N_bkg]))\n",
    "\n",
    "print(\"Mix f1 score:\", f1_score(y_mix, Fisher.predict(X_mix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples from Scikit-learn\n",
    "\n",
    "### [An introduction to machine learning with scikit-learn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digits.data[500].reshape((8,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(digits.data[:-1], digits.target[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(digits.data[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
